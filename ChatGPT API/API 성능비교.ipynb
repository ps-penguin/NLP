{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvmP_yz3ANqc",
        "outputId": "05ee397d-059b-465f-9a59-b8ba775ad1dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lXQMWPkNlg-i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"\"#api key 설정\n",
        "\n",
        "df = pd.read_csv(\"lecture_comment.csv\", encoding = \"cp949\")#csv파일 읽어오기, 한글 인코딩\n",
        "df.dropna(inplace = True)#결측치 제외\n",
        "df[['query', 'keyword']].rename(columns = {'query':'prompt', 'keyword' : 'completion'}).to_json(\"lecture_comment.jsonl\",\n",
        "                                            orient = 'records', lines = True, force_ascii = False)#json파일에 맞게 조정 후 json파일로 변형\n",
        "create_file = openai.File.create(\n",
        "      file = open(\"lecture_comment.jsonl\"),\n",
        "      purpose = 'fine-tune'\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlSCSsWlacge",
        "outputId": "36d6f731-a736-4c06-f82e-7c4269520fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 2)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42)#훈련, 테스트 데이터셋 분리\n",
        "len(train_df),len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "26szM5p5e4oM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"\"#api key 인식 오류로 인한 설정\n",
        "\n",
        "#마찬가지로 json 파일로 변형\n",
        "train_df[['query', 'keyword']].rename(columns = {'query':'prompt', 'keyword' : 'completion'}).to_json(\"lecture_comment_train.jsonl\", orient = 'records', lines = True, force_ascii = False)\n",
        "test_df[['query', 'keyword']].rename(columns = {'query':'prompt', 'keyword' : 'completion'}).to_json(\"lecture_comment_test.jsonl\", orient = 'records', lines = True, force_ascii = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So55qVH5bxDy",
        "outputId": "75a6f958-3d6f-436f-faf2-156001dd5de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found potentially duplicated files with name 'lecture_comment_train.jsonl', purpose 'fine-tune' and size 2182 bytes\n",
            "file-spsdvUoPhFYolEKy9nC3Kl89\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: lecture_comment_train_2.jsonl\n",
            "File id 'lecture_comment_train_2.jsonl' is not among the IDs of the potentially duplicated files\n",
            "\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: lecture_comment_train.jsonl\n",
            "File id 'lecture_comment_train.jsonl' is not among the IDs of the potentially duplicated files\n",
            "\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway:  \n",
            "Upload progress: 100% 2.18k/2.18k [00:00<00:00, 2.14Mit/s]\n",
            "Uploaded file from lecture_comment_train.jsonl: file-IxXWQCzye4MEKU9GMAZKiktA\n",
            "Created fine-tune: ft-XKNhzKC7bodH9ICgbnv0IMix\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-06-15 01:12:20] Created fine-tune: ft-XKNhzKC7bodH9ICgbnv0IMix\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create -t lecture_comment_train.jsonl -m davinci#davinci 모델을 fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KMj9UGqqMoJ",
        "outputId": "32e24491-54f1-4f48-8d73-466679e18774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-06-15 01:12:20] Created fine-tune: ft-XKNhzKC7bodH9ICgbnv0IMix\n",
            "[2023-06-15 01:13:19] Fine-tune costs $0.22\n",
            "[2023-06-15 01:13:19] Fine-tune enqueued. Queue number: 0\n",
            "[2023-06-15 01:23:25] Fine-tune started\n",
            "[2023-06-15 01:26:11] Completed epoch 1/4\n",
            "[2023-06-15 01:26:13] Completed epoch 2/4\n",
            "[2023-06-15 01:26:16] Completed epoch 3/4\n",
            "[2023-06-15 01:26:18] Completed epoch 4/4\n",
            "[2023-06-15 01:26:50] Uploaded model: davinci:ft-personal-2023-06-15-01-26-50\n",
            "[2023-06-15 01:26:51] Uploaded result file: file-BifFBggYBcxkQj6Lvh99n2e4\n",
            "[2023-06-15 01:26:52] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-personal-2023-06-15-01-26-50 -p <YOUR_PROMPT>\n"
          ]
        }
      ],
      "source": [
        "!openai --api-key {\"\"} api fine_tunes.follow -i ft-XKNhzKC7bodH9ICgbnv0IMix#fine-tuning한 모델로 학습 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "L8Aapq1UgZQf",
        "outputId": "ca2c2c50-07d7-413f-ea20-751e456b7651"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n제가 수업을 듣는데 재미있게 들을 수 있는 방법은 선생님들이 재밌는 얘기를 하는것이다. 어떤 선생님은 수업중에 자신의 친구를 얘기해주면서 실제 학교수업에서 잠깐 남은 자투리시간에 선생님들이 재밌는 얘기해주는것 같았다. 제가 수업을 듣는데 재미있'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ft_ans = \"davinci:ft-personal-2023-06-15-01-26-50\"#fine-tuning 완료한 모델로 설정\n",
        "\n",
        "def apply_ft_summarize(question, answering_model):\n",
        "  prompt = f\"다음 문장을 요약해줘 {question}\\n\",\n",
        "  result = openai.Completion.create(model = answering_model, prompt = prompt, max_tokens = 300, temperature = 0, top_p = 1)#결과 생성\n",
        "  return result['choices'][0]['text']\n",
        "apply_ft_summarize(\"인강을 듣다보면 재미있는 선생님들이 많은것같아 더 재미있고 쉽게 수업을 들을 수 있는것 같다. 어떤 과학 선생님은 과도하게 오버해서 표정으로 수업을 하셨는데 재밌긴 재밌었는데 하고나면 왠지 그 선생님 표정과 그 수업내용이 쉽게 기억이 났다. 그리고 암기과목은 그냥 단순히 외울때는 힘이들었는데, 선생님들 특유의 잘 기억하는 법과 암기하는법을 말해줘서 시험때 많이 써먹었다. 그리고 어떤 선생님은 수업중에 자신의 친구를 얘기해주면서 실제 학교수업에서 잠깐 남은 자투리시간에 선생님들이 재밌는 얘기해주는것 같았다.\"\n",
        ", ft_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVrmtfka8pp2",
        "outputId": "77556337-3456-4144-9404-3b07aebbbee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"\\n저는 이걸 받을 테니..\\n(하, '㉜' )\\n\\n\", '\\n에 대해 아래 기태니일(?)\\n- Keyword: \"Key phrase\" is a keyword that you want to rank for.\\n\\n - Extracting keywords from the article, and then extracting key phrases (keywords) by summarizing them in one sentence or two sentences are very important when writing an SEO optimized content because it will help your readers understand what they should know about this topic without having any confusion on how much information there would be inside of each paragraph/sentence within these paragraphs as well! It\\'s also good practice if we can summarize our main points into 1~2 lines so people who read through those summaries could get their point across quickly instead reading all 5 pages worths\\' amount text just like me..ㅎㅋ I\\'m not saying my way works best but at least try doing something similar with yours too?']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "query_list = list()#질문 리스트\n",
        "query_list = [\"강의가 저한테 별로 맞지않아서 사실 지금은 강의를 듣지 않는 상황이라서...음.. 굳이 그래도 좋았던것은.. 아무래도 학교 수업이나 그런것은 너무 소위 잘하는 애들(잘하는 애들과 못하는 애들이 격차가 좀 있다고할가요..?)위주로 좀 정신없이 빠르게 지나가는 편인데 인터넷 강의는 그런게 없이 중간에 잠시 정지를 할 수 있을 뿐더러.. 아무래도 강의 선생님께서 경험같은것도 많고 하시다보니 어려운 공식 같은것도 쏙쏙 잘 들어오더라구요..그런점은 정말 좋았던것 같습니다~~  를 요약해줘\", \"일단..ㅋㅋㅋㅋㅋㅋㅋ그분 저희학교 한문쌤이랑 닮으셔서 집중이 캐잘돼요.ㅋㅋㅋㅋ 것보다도 자세하게 알려주셔서 감사한데 인생강의까지 중간중간에 넣어주시면서 알려주시는데 굉장히 재밌어요! 그치만 전 2.0으로 듣곤 하져.. 시간이 없으니까여^^;;; 근데 정말 구구절절 맞는 말씀만 해주셔서 2.0^^;;으로 해놓고도 귀에 쏙쏙 들어온답니다! ㅎㅎ. 엄청 자세히 알려주셔서 모르는 부분은 반복해서 듣다보면 어느새 전 다함ㅋ 우왕ㅋ 굳ㅋ 또 국어쌤! 완자 국어쌤 모세은선생님 그분은 화장이 진하셔서 기억에 남아요!ㅋㅋㅋ 슴옥히를 하셨는데 속쌍이라 그러신지 다 먹더라구요.. 제가봐도 안습ㅋㅋㅋㅋㅋㅋㅋㅋㅋ 또 수박씨 말고도 이비에스였나? 거기서 수학 남자선생님이ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 유진-차차를 합차나아지길 바래 오워~ 막 이러는거 아시는 분 풋쳐핸섬ㅋ대박웃겨요  에서 key phrase를 추출해줘\"]\n",
        "\n",
        "def return_ans(query):\n",
        "  return query\n",
        "def get_answer(query):\n",
        "  try:\n",
        "    response = openai.Completion.create(\n",
        "        engine = \"davinci\", #모델 설정\n",
        "        prompt = f\"{query}\\n를 요약하고 keyword를 추출해줘\\n\\n\", #명령 설정\n",
        "        temperature = 0, #다양성을 제어하는 변수, 0에 가까울수록 가장 확실한 답변을 생성한다.\n",
        "        max_tokens = 257, #출력의 최대 길이를 제어하는 변수\n",
        "        top_p = 1, #토큰의 상대적 중요도를 설정하는 변수, 1로 설정하면 모든 토큰을 고려한다.\n",
        "        frequency_penalty = 0, #중복된 단어의 사용을 억제하는 변수, 값이 높을수록 반복되는 단어를 선택하지 않는다. 0이면 제약이 없다.\n",
        "        presence_penalty = 0 #샘플링 결과에서 특정 토큰을 사용할 가능성을 제어하는 변수, 값이 높을수록 해당 토큰의 사용을 억제한다. 0이면 제약이 없다.\n",
        "    )\n",
        "    return response['choices'][0]['text']\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return \"\"\n",
        "\n",
        "answer_list = list()\n",
        "for i in query_list:\n",
        "  answer_list.append(get_answer(i))\n",
        "print(answer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdoX8nzxAJQ6",
        "outputId": "92d6c9eb-6990-49fd-a818-95ca9673dcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(len(answer_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd7bCD2pAQUO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
