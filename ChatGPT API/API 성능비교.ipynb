{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvmP_yz3ANqc",
        "outputId": "05ee397d-059b-465f-9a59-b8ba775ad1dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lXQMWPkNlg-i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"\"#api key ì„¤ì •\n",
        "\n",
        "df = pd.read_csv(\"lecture_comment.csv\", encoding = \"cp949\")#csvíŒŒì¼ ì½ì–´ì˜¤ê¸°, í•œê¸€ ì¸ì½”ë”©\n",
        "df.dropna(inplace = True)#ê²°ì¸¡ì¹˜ ì œì™¸\n",
        "df[['query', 'keyword']].rename(columns = {'query':'prompt', 'keyword' : 'completion'}).to_json(\"lecture_comment.jsonl\",\n",
        "                                            orient = 'records', lines = True, force_ascii = False)#jsoníŒŒì¼ì— ë§ê²Œ ì¡°ì • í›„ jsoníŒŒì¼ë¡œ ë³€í˜•\n",
        "create_file = openai.File.create(\n",
        "      file = open(\"lecture_comment.jsonl\"),\n",
        "      purpose = 'fine-tune'\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlSCSsWlacge",
        "outputId": "36d6f731-a736-4c06-f82e-7c4269520fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 2)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42)#í›ˆë ¨, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
        "len(train_df),len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "26szM5p5e4oM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"\"#api key ì¸ì‹ ì˜¤ë¥˜ë¡œ ì¸í•œ ì„¤ì •\n",
        "\n",
        "#ë§ˆì°¬ê°€ì§€ë¡œ json íŒŒì¼ë¡œ ë³€í˜•\n",
        "train_df[['query', 'keyword']].rename(columns = {'query':'prompt', 'keyword' : 'completion'}).to_json(\"lecture_comment_train.jsonl\", orient = 'records', lines = True, force_ascii = False)\n",
        "test_df[['query', 'keyword']].rename(columns = {'query':'prompt', 'keyword' : 'completion'}).to_json(\"lecture_comment_test.jsonl\", orient = 'records', lines = True, force_ascii = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So55qVH5bxDy",
        "outputId": "75a6f958-3d6f-436f-faf2-156001dd5de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found potentially duplicated files with name 'lecture_comment_train.jsonl', purpose 'fine-tune' and size 2182 bytes\n",
            "file-spsdvUoPhFYolEKy9nC3Kl89\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: lecture_comment_train_2.jsonl\n",
            "File id 'lecture_comment_train_2.jsonl' is not among the IDs of the potentially duplicated files\n",
            "\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: lecture_comment_train.jsonl\n",
            "File id 'lecture_comment_train.jsonl' is not among the IDs of the potentially duplicated files\n",
            "\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway:  \n",
            "Upload progress: 100% 2.18k/2.18k [00:00<00:00, 2.14Mit/s]\n",
            "Uploaded file from lecture_comment_train.jsonl: file-IxXWQCzye4MEKU9GMAZKiktA\n",
            "Created fine-tune: ft-XKNhzKC7bodH9ICgbnv0IMix\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-06-15 01:12:20] Created fine-tune: ft-XKNhzKC7bodH9ICgbnv0IMix\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create -t lecture_comment_train.jsonl -m davinci#davinci ëª¨ë¸ì„ fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KMj9UGqqMoJ",
        "outputId": "32e24491-54f1-4f48-8d73-466679e18774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-06-15 01:12:20] Created fine-tune: ft-XKNhzKC7bodH9ICgbnv0IMix\n",
            "[2023-06-15 01:13:19] Fine-tune costs $0.22\n",
            "[2023-06-15 01:13:19] Fine-tune enqueued. Queue number: 0\n",
            "[2023-06-15 01:23:25] Fine-tune started\n",
            "[2023-06-15 01:26:11] Completed epoch 1/4\n",
            "[2023-06-15 01:26:13] Completed epoch 2/4\n",
            "[2023-06-15 01:26:16] Completed epoch 3/4\n",
            "[2023-06-15 01:26:18] Completed epoch 4/4\n",
            "[2023-06-15 01:26:50] Uploaded model: davinci:ft-personal-2023-06-15-01-26-50\n",
            "[2023-06-15 01:26:51] Uploaded result file: file-BifFBggYBcxkQj6Lvh99n2e4\n",
            "[2023-06-15 01:26:52] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ğŸ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-personal-2023-06-15-01-26-50 -p <YOUR_PROMPT>\n"
          ]
        }
      ],
      "source": [
        "!openai --api-key {\"\"} api fine_tunes.follow -i ft-XKNhzKC7bodH9ICgbnv0IMix#fine-tuningí•œ ëª¨ë¸ë¡œ í•™ìŠµ ì§„í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "L8Aapq1UgZQf",
        "outputId": "ca2c2c50-07d7-413f-ea20-751e456b7651"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nì œê°€ ìˆ˜ì—…ì„ ë“£ëŠ”ë° ì¬ë¯¸ìˆê²Œ ë“¤ì„ ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ì„ ìƒë‹˜ë“¤ì´ ì¬ë°ŒëŠ” ì–˜ê¸°ë¥¼ í•˜ëŠ”ê²ƒì´ë‹¤. ì–´ë–¤ ì„ ìƒë‹˜ì€ ìˆ˜ì—…ì¤‘ì— ìì‹ ì˜ ì¹œêµ¬ë¥¼ ì–˜ê¸°í•´ì£¼ë©´ì„œ ì‹¤ì œ í•™êµìˆ˜ì—…ì—ì„œ ì ê¹ ë‚¨ì€ ìíˆ¬ë¦¬ì‹œê°„ì— ì„ ìƒë‹˜ë“¤ì´ ì¬ë°ŒëŠ” ì–˜ê¸°í•´ì£¼ëŠ”ê²ƒ ê°™ì•˜ë‹¤. ì œê°€ ìˆ˜ì—…ì„ ë“£ëŠ”ë° ì¬ë¯¸ìˆ'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ft_ans = \"davinci:ft-personal-2023-06-15-01-26-50\"#fine-tuning ì™„ë£Œí•œ ëª¨ë¸ë¡œ ì„¤ì •\n",
        "\n",
        "def apply_ft_summarize(question, answering_model):\n",
        "  prompt = f\"ë‹¤ìŒ ë¬¸ì¥ì„ ìš”ì•½í•´ì¤˜ {question}\\n\",\n",
        "  result = openai.Completion.create(model = answering_model, prompt = prompt, max_tokens = 300, temperature = 0, top_p = 1)#ê²°ê³¼ ìƒì„±\n",
        "  return result['choices'][0]['text']\n",
        "apply_ft_summarize(\"ì¸ê°•ì„ ë“£ë‹¤ë³´ë©´ ì¬ë¯¸ìˆëŠ” ì„ ìƒë‹˜ë“¤ì´ ë§ì€ê²ƒê°™ì•„ ë” ì¬ë¯¸ìˆê³  ì‰½ê²Œ ìˆ˜ì—…ì„ ë“¤ì„ ìˆ˜ ìˆëŠ”ê²ƒ ê°™ë‹¤. ì–´ë–¤ ê³¼í•™ ì„ ìƒë‹˜ì€ ê³¼ë„í•˜ê²Œ ì˜¤ë²„í•´ì„œ í‘œì •ìœ¼ë¡œ ìˆ˜ì—…ì„ í•˜ì…¨ëŠ”ë° ì¬ë°Œê¸´ ì¬ë°Œì—ˆëŠ”ë° í•˜ê³ ë‚˜ë©´ ì™ ì§€ ê·¸ ì„ ìƒë‹˜ í‘œì •ê³¼ ê·¸ ìˆ˜ì—…ë‚´ìš©ì´ ì‰½ê²Œ ê¸°ì–µì´ ë‚¬ë‹¤. ê·¸ë¦¬ê³  ì•”ê¸°ê³¼ëª©ì€ ê·¸ëƒ¥ ë‹¨ìˆœíˆ ì™¸ìš¸ë•ŒëŠ” í˜ì´ë“¤ì—ˆëŠ”ë°, ì„ ìƒë‹˜ë“¤ íŠ¹ìœ ì˜ ì˜ ê¸°ì–µí•˜ëŠ” ë²•ê³¼ ì•”ê¸°í•˜ëŠ”ë²•ì„ ë§í•´ì¤˜ì„œ ì‹œí—˜ë•Œ ë§ì´ ì¨ë¨¹ì—ˆë‹¤. ê·¸ë¦¬ê³  ì–´ë–¤ ì„ ìƒë‹˜ì€ ìˆ˜ì—…ì¤‘ì— ìì‹ ì˜ ì¹œêµ¬ë¥¼ ì–˜ê¸°í•´ì£¼ë©´ì„œ ì‹¤ì œ í•™êµìˆ˜ì—…ì—ì„œ ì ê¹ ë‚¨ì€ ìíˆ¬ë¦¬ì‹œê°„ì— ì„ ìƒë‹˜ë“¤ì´ ì¬ë°ŒëŠ” ì–˜ê¸°í•´ì£¼ëŠ”ê²ƒ ê°™ì•˜ë‹¤.\"\n",
        ", ft_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVrmtfka8pp2",
        "outputId": "77556337-3456-4144-9404-3b07aebbbee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"\\nì €ëŠ” ì´ê±¸ ë°›ì„ í…Œë‹ˆ..\\n(í•˜, 'ã‰œ' )\\n\\n\", '\\nì— ëŒ€í•´ ì•„ë˜ ê¸°íƒœë‹ˆì¼(?)\\n- Keyword: \"Key phrase\" is a keyword that you want to rank for.\\n\\n - Extracting keywords from the article, and then extracting key phrases (keywords) by summarizing them in one sentence or two sentences are very important when writing an SEO optimized content because it will help your readers understand what they should know about this topic without having any confusion on how much information there would be inside of each paragraph/sentence within these paragraphs as well! It\\'s also good practice if we can summarize our main points into 1~2 lines so people who read through those summaries could get their point across quickly instead reading all 5 pages worths\\' amount text just like me..ã…ã…‹ I\\'m not saying my way works best but at least try doing something similar with yours too?']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "query_list = list()#ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n",
        "query_list = [\"ê°•ì˜ê°€ ì €í•œí…Œ ë³„ë¡œ ë§ì§€ì•Šì•„ì„œ ì‚¬ì‹¤ ì§€ê¸ˆì€ ê°•ì˜ë¥¼ ë“£ì§€ ì•ŠëŠ” ìƒí™©ì´ë¼ì„œ...ìŒ.. êµ³ì´ ê·¸ë˜ë„ ì¢‹ì•˜ë˜ê²ƒì€.. ì•„ë¬´ë˜ë„ í•™êµ ìˆ˜ì—…ì´ë‚˜ ê·¸ëŸ°ê²ƒì€ ë„ˆë¬´ ì†Œìœ„ ì˜í•˜ëŠ” ì• ë“¤(ì˜í•˜ëŠ” ì• ë“¤ê³¼ ëª»í•˜ëŠ” ì• ë“¤ì´ ê²©ì°¨ê°€ ì¢€ ìˆë‹¤ê³ í• ê°€ìš”..?)ìœ„ì£¼ë¡œ ì¢€ ì •ì‹ ì—†ì´ ë¹ ë¥´ê²Œ ì§€ë‚˜ê°€ëŠ” í¸ì¸ë° ì¸í„°ë„· ê°•ì˜ëŠ” ê·¸ëŸ°ê²Œ ì—†ì´ ì¤‘ê°„ì— ì ì‹œ ì •ì§€ë¥¼ í•  ìˆ˜ ìˆì„ ë¿ë”ëŸ¬.. ì•„ë¬´ë˜ë„ ê°•ì˜ ì„ ìƒë‹˜ê»˜ì„œ ê²½í—˜ê°™ì€ê²ƒë„ ë§ê³  í•˜ì‹œë‹¤ë³´ë‹ˆ ì–´ë ¤ìš´ ê³µì‹ ê°™ì€ê²ƒë„ ì™ì™ ì˜ ë“¤ì–´ì˜¤ë”ë¼êµ¬ìš”..ê·¸ëŸ°ì ì€ ì •ë§ ì¢‹ì•˜ë˜ê²ƒ ê°™ìŠµë‹ˆë‹¤~~  ë¥¼ ìš”ì•½í•´ì¤˜\", \"ì¼ë‹¨..ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ê·¸ë¶„ ì €í¬í•™êµ í•œë¬¸ìŒ¤ì´ë‘ ë‹®ìœ¼ì…”ì„œ ì§‘ì¤‘ì´ ìºì˜ë¼ìš”.ã…‹ã…‹ã…‹ã…‹ ê²ƒë³´ë‹¤ë„ ìì„¸í•˜ê²Œ ì•Œë ¤ì£¼ì…”ì„œ ê°ì‚¬í•œë° ì¸ìƒê°•ì˜ê¹Œì§€ ì¤‘ê°„ì¤‘ê°„ì— ë„£ì–´ì£¼ì‹œë©´ì„œ ì•Œë ¤ì£¼ì‹œëŠ”ë° êµ‰ì¥íˆ ì¬ë°Œì–´ìš”! ê·¸ì¹˜ë§Œ ì „ 2.0ìœ¼ë¡œ ë“£ê³¤ í•˜ì ¸.. ì‹œê°„ì´ ì—†ìœ¼ë‹ˆê¹Œì—¬^^;;; ê·¼ë° ì •ë§ êµ¬êµ¬ì ˆì ˆ ë§ëŠ” ë§ì”€ë§Œ í•´ì£¼ì…”ì„œ 2.0^^;;ìœ¼ë¡œ í•´ë†“ê³ ë„ ê·€ì— ì™ì™ ë“¤ì–´ì˜¨ë‹µë‹ˆë‹¤! ã…ã…. ì—„ì²­ ìì„¸íˆ ì•Œë ¤ì£¼ì…”ì„œ ëª¨ë¥´ëŠ” ë¶€ë¶„ì€ ë°˜ë³µí•´ì„œ ë“£ë‹¤ë³´ë©´ ì–´ëŠìƒˆ ì „ ë‹¤í•¨ã…‹ ìš°ì™•ã…‹ êµ³ã…‹ ë˜ êµ­ì–´ìŒ¤! ì™„ì êµ­ì–´ìŒ¤ ëª¨ì„¸ì€ì„ ìƒë‹˜ ê·¸ë¶„ì€ í™”ì¥ì´ ì§„í•˜ì…”ì„œ ê¸°ì–µì— ë‚¨ì•„ìš”!ã…‹ã…‹ã…‹ ìŠ´ì˜¥íˆë¥¼ í•˜ì…¨ëŠ”ë° ì†ìŒì´ë¼ ê·¸ëŸ¬ì‹ ì§€ ë‹¤ ë¨¹ë”ë¼êµ¬ìš”.. ì œê°€ë´ë„ ì•ˆìŠµã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë˜ ìˆ˜ë°•ì”¨ ë§ê³ ë„ ì´ë¹„ì—ìŠ¤ì˜€ë‚˜? ê±°ê¸°ì„œ ìˆ˜í•™ ë‚¨ìì„ ìƒë‹˜ì´ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ìœ ì§„-ì°¨ì°¨ë¥¼ í•©ì°¨ë‚˜ì•„ì§€ê¸¸ ë°”ë˜ ì˜¤ì›Œ~ ë§‰ ì´ëŸ¬ëŠ”ê±° ì•„ì‹œëŠ” ë¶„ í’‹ì³í•¸ì„¬ã…‹ëŒ€ë°•ì›ƒê²¨ìš”  ì—ì„œ key phraseë¥¼ ì¶”ì¶œí•´ì¤˜\"]\n",
        "\n",
        "def return_ans(query):\n",
        "  return query\n",
        "def get_answer(query):\n",
        "  try:\n",
        "    response = openai.Completion.create(\n",
        "        engine = \"davinci\", #ëª¨ë¸ ì„¤ì •\n",
        "        prompt = f\"{query}\\në¥¼ ìš”ì•½í•˜ê³  keywordë¥¼ ì¶”ì¶œí•´ì¤˜\\n\\n\", #ëª…ë ¹ ì„¤ì •\n",
        "        temperature = 0, #ë‹¤ì–‘ì„±ì„ ì œì–´í•˜ëŠ” ë³€ìˆ˜, 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°€ì¥ í™•ì‹¤í•œ ë‹µë³€ì„ ìƒì„±í•œë‹¤.\n",
        "        max_tokens = 257, #ì¶œë ¥ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì œì–´í•˜ëŠ” ë³€ìˆ˜\n",
        "        top_p = 1, #í† í°ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ë¥¼ ì„¤ì •í•˜ëŠ” ë³€ìˆ˜, 1ë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  í† í°ì„ ê³ ë ¤í•œë‹¤.\n",
        "        frequency_penalty = 0, #ì¤‘ë³µëœ ë‹¨ì–´ì˜ ì‚¬ìš©ì„ ì–µì œí•˜ëŠ” ë³€ìˆ˜, ê°’ì´ ë†’ì„ìˆ˜ë¡ ë°˜ë³µë˜ëŠ” ë‹¨ì–´ë¥¼ ì„ íƒí•˜ì§€ ì•ŠëŠ”ë‹¤. 0ì´ë©´ ì œì•½ì´ ì—†ë‹¤.\n",
        "        presence_penalty = 0 #ìƒ˜í”Œë§ ê²°ê³¼ì—ì„œ íŠ¹ì • í† í°ì„ ì‚¬ìš©í•  ê°€ëŠ¥ì„±ì„ ì œì–´í•˜ëŠ” ë³€ìˆ˜, ê°’ì´ ë†’ì„ìˆ˜ë¡ í•´ë‹¹ í† í°ì˜ ì‚¬ìš©ì„ ì–µì œí•œë‹¤. 0ì´ë©´ ì œì•½ì´ ì—†ë‹¤.\n",
        "    )\n",
        "    return response['choices'][0]['text']\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return \"\"\n",
        "\n",
        "answer_list = list()\n",
        "for i in query_list:\n",
        "  answer_list.append(get_answer(i))\n",
        "print(answer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdoX8nzxAJQ6",
        "outputId": "92d6c9eb-6990-49fd-a818-95ca9673dcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(len(answer_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd7bCD2pAQUO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
